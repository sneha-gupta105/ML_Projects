# -*- coding: utf-8 -*-
"""AI-Powered Insurance Fraud Detection System.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1wMF0XOtKiRqiqc2MwVvD0lY_oQmDJrAp
"""

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

df= pd.read_csv('/content/Final_insurance_fraud.csv')
print(df.shape)
df.head()

"""##Data Visualization and Cleaning"""

sns.set(style="whitegrid")

# 1. Bar plot showing count of missing values per column
missing_counts = df.isnull().sum()
missing_counts = missing_counts[missing_counts > 0]

plt.figure(figsize=(10, 5))
missing_counts.sort_values(ascending=False).plot(kind='bar', color='salmon')
plt.title("Missing Values per Column")
plt.xlabel("Columns")
plt.ylabel("Count of Missing Values")
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

# 2. Heatmap of missing values
plt.figure(figsize=(12, 6))
sns.heatmap(df.isnull(), cbar=False, cmap='viridis', yticklabels=False)
plt.title("Heatmap of Missing Data")
plt.show()

print("Missing values per column:")
print(df.isnull().sum())

from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.pipeline import Pipeline
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, accuracy_score

# Selected features
text_feature = 'Claim_Description'
numeric_features = [
    'Customer_Age', 'Claim_Amount', 'Claim_Frequency',
    'Coverage Amount', 'Premium Amount', 'Deductible',
    'Interactions with Customer Service'
]
categorical_features = [
    'Policy_Type', 'Incident_Severity', 'Occupation',
    'Education Level', 'Driving Record', 'Claim_History'
]

# Combine all features
X = df_cleaned[[text_feature] + numeric_features + categorical_features]
y = df_cleaned['Fraud_Label']

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, stratify=y, random_state=42)

# Preprocessing pipeline
preprocessor = ColumnTransformer(transformers=[
    ('text', TfidfVectorizer(stop_words='english', max_features=1000), text_feature),
    ('num', StandardScaler(), numeric_features),
    ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)
])

# Full pipeline
pipeline = Pipeline([
    ('preprocess', preprocessor),
    ('clf', LogisticRegression(solver='liblinear'))
])

# Train and evaluate
pipeline.fit(X_train, y_train)
y_pred = pipeline.predict(X_test)

# Results
print("=== Classification Report ===")
print(classification_report(y_test, y_pred))
print("Accuracy:", accuracy_score(y_test, y_pred))

plt.figure(figsize=(6, 4))
sns.countplot(x='Fraud_Label', data=df, palette='Set2')
plt.title('Distribution of Fraud vs Non-Fraud Claims')
plt.xlabel('Fraud Label (0 = Not Fraud, 1 = Fraud)')
plt.ylabel('Number of Claims')
plt.xticks([0, 1])
plt.tight_layout()
plt.show()

df_cleaned = df.dropna()

plt.figure(figsize=(6, 4))
sns.countplot(x='Fraud_Label', data=df_cleaned, palette='Set2')
plt.title('Distribution of Fraud vs Non-Fraud Claims')
plt.xlabel('Fraud Label (0 = Not Fraud, 1 = Fraud)')
plt.ylabel('Number of Claims')
plt.xticks([0, 1])
plt.tight_layout()
plt.show()

print(df_cleaned.shape)

"""##NLP based model"""

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.pipeline import Pipeline
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, accuracy_score



# Step 1: Extract text features and labels
X = df_cleaned['Claim_Description']
y = df_cleaned['Fraud_Label']

# Split into train/test sets
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, random_state=42, stratify=y)

# Create the NLP classification pipeline
nlp_pipeline = Pipeline([
    ('tfidf', TfidfVectorizer(stop_words='english', max_features=1000)),
    ('clf', LogisticRegression(solver='liblinear'))
])

# Train the model
nlp_pipeline.fit(X_train, y_train)

#  Predict on test set
y_pred = nlp_pipeline.predict(X_test)

# Step 6: Evaluation
print("=== Classification Report ===")
print(classification_report(y_test, y_pred))

print("Accuracy:", accuracy_score(y_test, y_pred))

"""## NLP + Logistic regression (complete dataset , with imp features used)"""

from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.pipeline import Pipeline
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, accuracy_score

# Define features and target
text_feature = 'Claim_Description'
numeric_features = ['Customer_Age', 'Claim_Amount', 'Claim_History',
                    'Claim_Frequency', 'Coverage Amount', 'Premium Amount', 'Deductible']
categorical_features = ['Policy_Type', 'Incident_Severity', 'Occupation']
target = 'Fraud_Label'

# Filter relevant columns and drop missing rows
required_cols = [text_feature] + numeric_features + categorical_features + [target]
df_model = df_cleaned[required_cols].dropna()

# Split features and target
X = df_model.drop(columns=[target])
y = df_model[target]

# Preprocessor
preprocessor = ColumnTransformer([
    ('text', TfidfVectorizer(stop_words='english', max_features=1000), 'Claim_Description'),
    ('num', StandardScaler(), numeric_features),
    ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)
])

# Pipeline
pipeline = Pipeline([
    ('preprocess', preprocessor),
    ('clf', LogisticRegression(solver='liblinear'))
])

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(
    X, y, stratify=y, test_size=0.3, random_state=42)

# Fit and evaluate
pipeline.fit(X_train, y_train)
y_pred = pipeline.predict(X_test)

print("=== Classification Report ===")
print(classification_report(y_test, y_pred))
print("Accuracy:", accuracy_score(y_test, y_pred))

print("=== Label Distribution in Test Set ===")
print(y_test.value_counts())

"""## NLP + Randomforest based model"""

from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.ensemble import RandomForestClassifier
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, accuracy_score

# Define feature categories
numerical_features = [
    'Customer_Age', 'Claim_Amount', 'Claim_Frequency',
    'Coverage Amount', 'Premium Amount', 'Deductible'
]

categorical_features = [
    'Policy_Type', 'Incident_Severity', 'Gender', 'Marital Status',
    'Occupation', 'Income Level', 'Education Level', 'Location',
    'Behavioral Data', 'Purchase History', 'Customer Preferences',
    'Preferred Communication Channel', 'Driving Record', 'Life Events',
    'Insurance Products Owned', 'Claim_History'
]

text_feature = 'Claim_Description'

# Preprocessor
preprocessor = ColumnTransformer(transformers=[
    ('text', TfidfVectorizer(stop_words='english', max_features=1000), text_feature),
    ('num', StandardScaler(), numerical_features),
    ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)
])

# Full pipeline
full_pipeline = Pipeline([
    ('preprocess', preprocessor),
    ('clf', RandomForestClassifier(random_state=42))
])

# Define X and y
X = df_cleaned[[text_feature] + numerical_features + categorical_features]
y = df_cleaned['Fraud_Label']

# Train/test split
X_train, X_test, y_train, y_test = train_test_split(
    X, y, stratify=y, test_size=0.3, random_state=42)

# Train model
full_pipeline.fit(X_train, y_train)
y_pred = full_pipeline.predict(X_test)

# Evaluation
print("Accuracy:", accuracy_score(y_test, y_pred))
print(classification_report(y_test, y_pred))

import numpy as np

# Get prediction probabilities
y_prob = full_pipeline.predict_proba(X_test)

# Flag claims with *any* uncertainty (excluding those with >99% or <1% confidence)
human_review_idx = np.where((y_prob[:, 1] > 0.02) & (y_prob[:, 1] < 0.80))[0]
print(f"Claims needing review (1%-99% fraud chance): {len(human_review_idx)}")

# Get those rows
claims_needing_review = X_test.iloc[human_review_idx]

# Generate summaries
def generate_summary(claim_row):
    return f"""Claim Summary:
    - Age: {claim_row['Customer_Age']}
    - Claim Amount: ${claim_row['Claim_Amount']}
    - Description: {claim_row['Claim_Description'][:100]}..."""

# Print summaries
for idx, row in claims_needing_review.iterrows():
    print(generate_summary(row))
    print("-" * 60)

!pip install -q transformers accelerate

from transformers import AutoTokenizer, AutoModelForCausalLM
import torch

# Load tokenizer and model
model_id = "microsoft/phi-2"  # You can try mistralai/Mistral-7B-Instruct too, but itâ€™s heavy.

tokenizer = AutoTokenizer.from_pretrained(model_id)
model = AutoModelForCausalLM.from_pretrained(
    model_id,
    torch_dtype=torch.float16,
    device_map="auto"  # Use 'cpu' if no GPU available
)

def format_prompt(claim):
    return (
        f"Summarize the following insurance claim for human review:\n"
        f"Customer Age: {claim['Customer_Age']}, "
        f"Claim Amount: ${claim['Claim_Amount']}, "
        f"Policy Type: {claim['Policy_Type']}, "
        f"Incident Severity: {claim['Incident_Severity']}, "
        f"Occupation: {claim['Occupation']}, "
        f"Description: {claim['Claim_Description']}\n"
        f"Summary:"
    )

"""## Generate Summary for human intervention"""

def generate_phi_summary(prompt):
    inputs = tokenizer(prompt, return_tensors="pt").to(model.device)
    outputs = model.generate(**inputs, max_new_tokens=100, do_sample=True, top_p=0.9)
    return tokenizer.decode(outputs[0], skip_special_tokens=True).split("Summary:")[-1].strip()

for i, (_, row) in enumerate(claims_needing_review.reset_index(drop=True).iterrows()):
    prompt = format_prompt(row)
    summary = generate_phi_summary(prompt)
    prob = y_prob[human_review_idx[i], 1] * 100  # Map correct probability
    print(f"ðŸ”¥ Fraud Probability: {prob:.2f}%")
    print(summary)
    print("=" * 80)

"""## Sending Emails to approved claims(these mails can be sent using the sending id and receivers id , if available, (Smtp) ,"""

# Step 1: Auto-approval (fraud probability â‰¤ 2%)
auto_approved_idx = np.where(y_prob[:, 1] <= 0.02)[0]

# Step 2: Exclude human review cases
auto_approved_final_idx = list(set(auto_approved_idx) - set(human_review_idx))

# Step 3: Extract approved claims
auto_approved_claims = X_test.iloc[auto_approved_final_idx]

def send_approval_email(row):
    return f"""
ðŸ“¨ Email to Customer:

Subject: Insurance Claim Approved âœ…

Dear Valued Customer,

We are pleased to inform you that your insurance claim has been reviewed and approved.

ðŸ§¾ Claim Summary:
- Customer Age: {row['Customer_Age']}
- Claim Amount: ${row['Claim_Amount']}
- Policy Type: {row.get('Policy_Type', 'N/A')}
- Incident Severity: {row.get('Incident_Severity', 'N/A')}
- Description: {row['Claim_Description'][:100]}...

No further action is required from your side.

Thank you for trusting us with your insurance needs.

Warm regards,
Claims Approval Team
"""

# Send email simulation
for _, row in auto_approved_claims.iterrows():
    print(send_approval_email(row))
    print("=" * 100)