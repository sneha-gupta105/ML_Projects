# -*- coding: utf-8 -*-
"""Credit_Card_fraud_detection.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/11Cdi0fjB30uHdYSIo_07hVdAZlIcmAR2

##Including Libraries
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import confusion_matrix as cm
from sklearn.metrics import ConfusionMatrixDisplay as cmd
from sklearn.model_selection import train_test_split
from sklearn.metrics import f1_score
from sklearn import tree
from sklearn.ensemble import AdaBoostClassifier
from xgboost import XGBClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
from sklearn.ensemble import IsolationForest
from sklearn.neural_network import MLPClassifier
from sklearn.model_selection import cross_val_score as cvscore
from sklearn.metrics import roc_auc_score

from google.colab import drive
drive.mount('/content/drive')

cc_data=pd.read_csv('/content/drive/MyDrive/creditcard.csv')
data = pd.read_csv('/content/drive/MyDrive/creditcard.csv')
df = pd.DataFrame(data)
display(df)
cc_data.head()

"""The given data is having 31 columns out of which 30 are features and 1 is labels or targets

##Data Visualization
"""

cc_data['Class'].unique()
unique_count=[0,0]
for i in range(len(cc_data['Class'])):
  unique_count[cc_data['Class'][i]]+=1
print('Not Fraud Values are:-',unique_count[0])
print('Fraud Values are:-',unique_count[1])

plt.bar([0,1],unique_count,width=0.1,color='orange')
plt.xlabel('Type')
plt.ylabel('Count')
plt.title('Visualization of classes')
plt.grid()
plt.show()

"""### We can see that the data is totally biased most of the data is of non fraud values and having very less fraud values. We can deduce following points from it-->


*   The accuracy alone is not a good measure to check model so we will have to look for more measures.


*   Normal sampling technique will not work, either we will have to repeat data is this or have to use new sampling techniques







"""

h = np.arange(0,len(cc_data['V1']))

plt.scatter(h,cc_data['V1'],c=cc_data['Class'])
plt.grid()
plt.xlabel('Sample no.')
plt.ylabel('V1')
plt.show()

for columns in cc_data:
  plt.scatter(h,cc_data[columns],c=cc_data['Class'])
  plt.grid()
  plt.xlabel('Sample no.')
  plt.ylabel(columns)
  plt.show()

"""### we can see the data is well distributed and continous"""

cc_data.describe()

"""*Data* is already normalized so no preprocessing is required

Function for visualization
"""

def visualize(model_name,ytrue,ypred):
  metrix=[0,0,0,0]
  for i in range(len(ypred)):
    if(ytrue[i]==0 and ypred[i]==0):
      metrix[0]+=1#true negative
    elif(ytrue[i]==0 and ypred[i]==1):
      metrix[1]+=1#false positive
    elif(ytrue[i]==1 and ypred[i]==0):
      metrix[2]+=1#false negative
    elif(ytrue[i]==1 and ypred[i]==1):
      metrix[3]+=1#true positive
  # Precision
  if metrix[3]+metrix[1]==0:
    precision=None
  else:
    precision=metrix[3]/(metrix[3]+metrix[1])
  # Recall
  if metrix[3]+metrix[2]==0:
    recall=None
  else:
    recall=metrix[3]/(metrix[3]+metrix[2])
  # Sensitivity
  sensitivity=recall
  # Specificity
  if metrix[0]+metrix[1]==0:
    specificity=None
  else:
    specificity=metrix[0]/(metrix[0]+metrix[1])
  # Accuracy Score
  accuracy=(metrix[3]+metrix[0])/len(ypred)
  # F1 Score
  if (precision==None or recall==None):
    f1score=None
  else:
    #print(precision)
    #print(recall)
    f1score=f1_score(ytrue, ypred, zero_division=1,average='weighted')
  # ROC AUC Score
  ROCAUC = roc_auc_score(ytrue,ypred)
  #plotting
  data = {'Negpred': [metrix[0], metrix[2]],
        'Pospred': [metrix[1],metrix[3]]}
  data=pd.DataFrame(data)
  data1={'Metric Type':['Precision','Recall','Sensitivity','Specificity','Accuracy','F1 Score','AUC ROC Score'],'Metric Value':[precision,recall,sensitivity,specificity,accuracy,f1score,ROCAUC]}
  data1=pd.DataFrame(data1)

  print("This is for model",model_name)
  print()
  print('Confusion matrix for ',model_name)
  print('')
  print(data1)
  print()


  Cm = cm(ytrue, ypred, labels=[0,1])
  disp = cmd(confusion_matrix=Cm,display_labels=[0,1])
  disp.plot()
  plt.show()
  print("")
  print("")
  print("")
  print("")
  print("")
  return

# Seperating dependent and independent columns
X=cc_data.drop(['Class'],axis=1).values
Y=cc_data['Class'].values
X_train, X_test, Y_train, Y_test = train_test_split(
X,Y , random_state=0,test_size=0.2, shuffle=True)

# Training and visualizing accuracy metrics
def ModelScore(X,Y,X_train,Y_train,X_test,Y_test,model,model_name):
  a = model.fit(X_train,Y_train)
  predicted = a.predict(X_test)
  visualize(model_name,Y_test,predicted)


dtc=tree.DecisionTreeClassifier()
ModelScore(X,Y,X_train,Y_train,X_test,Y_test,dtc,'Decision Tree')

adbc=AdaBoostClassifier()
ModelScore(X,Y,X_train,Y_train,X_test,Y_test,adbc,'AdaBoost')

xgbc=XGBClassifier()
ModelScore(X,Y,X_train,Y_train,X_test,Y_test,xgbc,'XGBoost')

knnc=KNeighborsClassifier()
ModelScore(X,Y,X_train,Y_train,X_test,Y_test,knnc,'K Nearest Neighbours')

svmc=SVC()
ModelScore(X,Y,X_train,Y_train,X_test,Y_test,svmc,'Support Vector Machine')

ldac=LinearDiscriminantAnalysis()
ModelScore(X,Y,X_train,Y_train,X_test,Y_test,ldac,'LDA Classifier')

mlpc = MLPClassifier()
ModelScore(X,Y,X_train,Y_train,X_test,Y_test,mlpc,'Multilayered perceptron neural network')

"""##Sampling1"""

normal = df[df['Class'] == 0]
fraud = df[df['Class'] == 1]
sample_normal = normal.sample(frac = 0.1, random_state = 42)
sample_fraud = fraud.sample(frac = 0.1, random_state = 42)
sample_data = pd.concat([sample_normal, sample_fraud])                          # Keeping the proportion of positive and negative class same as original dataset
np.shape(sample_data)

# Seperating dependent and independent columns
X=sample_data.drop(['Class'],axis=1).values
Y=sample_data['Class'].values
X_train, X_test, Y_train, Y_test = train_test_split(
X,Y , random_state=0,test_size=0.2, shuffle=True)

# Training and visualizing accuracy metrics
def ModelScore(X,Y,X_train,Y_train,X_test,Y_test,model,model_name):
  model = model.fit(X_train,Y_train)
  predicted = model.predict(X_test)
  visualize(model_name,Y_test,predicted)

dtc=tree.DecisionTreeClassifier()
ModelScore(X,Y,X_train,Y_train,X_test,Y_test,dtc,'Decision Tree')

adbc=AdaBoostClassifier()
ModelScore(X,Y,X_train,Y_train,X_test,Y_test,adbc,'AdaBoost')

xgbc=XGBClassifier()
ModelScore(X,Y,X_train,Y_train,X_test,Y_test,xgbc,'XGBoost')

knnc=KNeighborsClassifier()
ModelScore(X,Y,X_train,Y_train,X_test,Y_test,knnc,'K Nearest Neighbours')
svmc=SVC()
ModelScore(X,Y,X_train,Y_train,X_test,Y_test,svmc,'Support Vector Machine')


ldac=LinearDiscriminantAnalysis()
ModelScore(X,Y,X_train,Y_train,X_test,Y_test,ldac,'LDA Classifier')

mlpc = MLPClassifier()
ModelScore(X,Y,X_train,Y_train,X_test,Y_test,mlpc,'Multilayered perceptron neural network')

"""##sampling 2"""

sample_normal2 = normal.sample(frac = 492/284315, random_state = 42)
sample_data2 = pd.concat([sample_normal2, fraud])                               #Taking equal number of positive and negative classes
np.shape(sample_normal2)

# Seperating dependent and independent columns
X=sample_data2.drop(['Class'],axis=1).values
Y=sample_data2['Class'].values
X_train, X_test, Y_train, Y_test = train_test_split(
X,Y , random_state=0,test_size=0.2, shuffle=True)

# Training and visualizing accuracy metrics
def ModelScore(X,Y,X_train,Y_train,X_test,Y_test,model,model_name):
  model = model.fit(X_train,Y_train)
  predicted = model.predict(X_test)
  visualize(model_name,Y_test,predicted)

dtc=tree.DecisionTreeClassifier()
ModelScore(X,Y,X_train,Y_train,X_test,Y_test,dtc,'Decision Tree')

adbc=AdaBoostClassifier()
ModelScore(X,Y,X_train,Y_train,X_test,Y_test,adbc,'AdaBoost')

xgbc=XGBClassifier()
ModelScore(X,Y,X_train,Y_train,X_test,Y_test,xgbc,'XGBoost')

knnc=KNeighborsClassifier()
ModelScore(X,Y,X_train,Y_train,X_test,Y_test,knnc,'K Nearest Neighbours')
svmc=SVC()
ModelScore(X,Y,X_train,Y_train,X_test,Y_test,svmc,'Support Vector Machine')


ldac=LinearDiscriminantAnalysis()
ModelScore(X,Y,X_train,Y_train,X_test,Y_test,ldac,'LDA Classifier')

"""mlpc = MLPClassifier()
ModelScore(X_train,Y_train,X_test,Y_test,mlpc,'Multilayered perceptron neural network')

##sampling 3
"""

normal_under = normal.sample(15000, random_state = 42)
fraud_over = fraud.sample(15000, replace = True)
sample_data3 = pd.concat([normal_under, fraud_over])                               #Taking equal number of positive and negative classes
np.shape(sample_data3)

# Seperating dependent and independent columns
X=sample_data3.drop(['Class'],axis=1).values
Y=sample_data3['Class'].values
X_train, X_test, Y_train, Y_test = train_test_split(
X,Y , random_state=0,test_size=0.2, shuffle=True)

# Training and visualizing accuracy metrics
def ModelScore(X,Y,X_train,Y_train,X_test,Y_test,model,model_name):
  model = model.fit(X_train,Y_train)
  predicted = model.predict(X_test)
  visualize(model_name,Y_test,predicted)

dtc=tree.DecisionTreeClassifier()
ModelScore(X,Y,X_train,Y_train,X_test,Y_test,dtc,'Decision Tree')

adbc=AdaBoostClassifier()
ModelScore(X,Y,X_train,Y_train,X_test,Y_test,adbc,'AdaBoost')

xgbc=XGBClassifier()
ModelScore(X,Y,X_train,Y_train,X_test,Y_test,xgbc,'XGBoost')

knnc=KNeighborsClassifier()
ModelScore(X,Y,X_train,Y_train,X_test,Y_test,knnc,'K Nearest Neighbours')
svmc=SVC()
ModelScore(X,Y,X_train,Y_train,X_test,Y_test,svmc,'Support Vector Machine')


ldac=LinearDiscriminantAnalysis()
ModelScore(X,Y,X_train,Y_train,X_test,Y_test,ldac,'LDA Classifier')

mlpc = MLPClassifier()
ModelScore(X,Y,X_train,Y_train,X_test,Y_test,mlpc,'Multilayered perceptron neural network')