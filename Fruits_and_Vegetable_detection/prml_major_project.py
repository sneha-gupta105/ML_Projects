# -*- coding: utf-8 -*-
"""prml_major_project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1i1sJFkfQg3ZKKqND4hATBH8PilhSc3Zs
"""

import numpy as np
import pandas as pd
import tensorflow as tf
from tensorflow import keras
import matplotlib.pyplot as plt
import os
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import accuracy_score

! pip install kaggle
! mkdir ~/.kaggle
! cp kaggle.json ~/.kaggle/
! chmod 600 ~/.kaggle/kaggle.json
! kaggle datasets download kritikseth/fruit-and-vegetable-image-recognition

! unzip fruit-and-vegetable-image-recognition.zip

import matplotlib.pyplot as plt
from PIL import Image

image = Image.open('/content/train/apple/Image_'+str(57)+'.jpg')
plt.imshow(image)
plt.show()
np_image = np.asarray(image)
print(np_image.shape)

"""##extracting names of fruits and vegetables"""

fruveg=[]
for name in os.listdir('/content/validation'):
  fruveg.append(name)
print((fruveg))

#making a dictionary pairing each fruit or vegetable with a key
fruitdict={}
for i in range(len(fruveg)):
  fruitdict[i]=fruveg[i]
print(fruitdict)

train_folder_path = '/content/train'

"""##training data visualization*"""

import os
import random
train_labelled=[]
fig1, axs1 = plt.subplots(6, 6, figsize=(15, 15))
i=0
j=0
for name in os.listdir('/content/train'):
    folder_path = os.path.join('/content/train', name) #creates the path of the current subfolder.
    if os.path.isdir(folder_path): #check if it is a directory
        file_names = os.listdir(folder_path) #list of the names of files in current directory
        if len(file_names) > 0:
            file_name = (file_names[0])
            file_path = os.path.join(folder_path, file_name)
            image = Image.open(file_path)
            train_labelled.append((np.asarray(image),name))
            if i>=6:
              i=0
              j+=1;
            axs1[i, j].imshow(image)
            axs1[i, j].set_title(name)
            axs1[i, j].axis('off')
            i=i+1;
plt.show()

print(np.shape(train_labelled[0][0]))

"""##Testing data visualization"""

import os
import random
fig2, axs2 = plt.subplots(6, 6, figsize=(15, 15))
i=0
j=0
for name in os.listdir('/content/test'):
    folder_path = os.path.join('/content/test', name) #creates the path of the current subfolder.
    if os.path.isdir(folder_path): #check if it is a directory
        file_names = os.listdir(folder_path) #list of the names of files in current directory
        if len(file_names) > 0:
            file_name = (random.choice(file_names))#printing random images
            file_path = os.path.join(folder_path, file_name)
            image = Image.open(file_path)

            if i>=6:
              i=0
              j+=1;
            axs2[i, j].imshow(image)
            axs2[i, j].set_title(name)
            axs2[i, j].axis('off')
            i=i+1;
plt.show()

"""##Validation data visualization"""

import os
import random
fig3, axs3 = plt.subplots(6, 6, figsize=(15, 15))
i=0
j=0
for name in os.listdir('/content/validation'):
    folder_path = os.path.join('/content/validation', name) #creates the path of the current subfolder.
    if os.path.isdir(folder_path): #check if it is a directory
        file_names = os.listdir(folder_path) #list of the names of files in current directory
        if len(file_names) > 0:
            file_name = (random.choice(file_names))
            file_path = os.path.join(folder_path, file_name)
            image = Image.open(file_path)

            if i>=6:
              i=0
              j+=1;
            axs3[i, j].imshow(image)
            axs3[i, j].set_title(name)
            axs3[i, j].axis('off')
            i=i+1;
plt.show()

# # Labelling the images
# i=0
# train_labelled=[]
# for name in os.listdir('/content/train'):
#     folder_path = os.path.join('/content/train', name) #creates the path of the current subfolder.
#     if os.path.isdir(folder_path): #check if it is a directory
#         file_names = os.listdir(folder_path) #list of the names of files in current directory
#         for img_name in file_names:
#             file_path = os.path.join(folder_path, img_name)
#             image = Image.open(file_path)
#             resized_image = image.resize((64, 64),3)
#             train_labelled.append([np.asarray(resized_image),name])
#             print(i)
#             i+=1

"""#part1

### Loading Training Data
"""

training_directory='/content/train' #address of data stored in drive using kaggle api
testing_directory='/content/test'
validation_directory='/content/validation'
train_set=tf.keras.utils.image_dataset_from_directory(
    training_directory,
    labels="inferred",#to take labels directly from subfolder names
    label_mode="categorical",#labels are encoded as a categorical vector
    color_mode="rgb",#colored or 3d images
    batch_size=64,
    image_size=(128, 128),
    shuffle=True,#mixing data
    seed=None,
    validation_split=None,#validation data is different no divide req
    interpolation="bilinear",#method for resizing
)

import matplotlib.pyplot as plt

# get the first batch of images and labels
for images, labels in train_set.take(1):
    # plot the first 9 images
    fig, axs = plt.subplots(3, 3, figsize=(10,10))
    axs = axs.flatten()
    for img, ax in zip(images, axs):
        ax.imshow(img.numpy().astype('uint8'))
        ax.axis('off')
    plt.tight_layout()
    plt.show()

"""data has been loaded for training set. now we will go for validation and testing data

###validation data
"""

val_set=tf.keras.utils.image_dataset_from_directory(
    validation_directory,
    labels="inferred",#to take labels directly from subfolder names
    label_mode="categorical",#labels are encoded as a categorical vector
    color_mode="rgb",#colored or 3d images
    batch_size=64,
    image_size=(128, 128),
    shuffle=True,#mixing data
    seed=None,
    validation_split=None,#validation data is different no divide req
    interpolation="bilinear",#method for resizing
)

"""###testing data"""

test_set=tf.keras.utils.image_dataset_from_directory(
    testing_directory,
    labels="inferred",#to take labels directly from subfolder names
    label_mode="categorical",#labels are encoded as a categorical vector
    color_mode="rgb",#colored or 3d images
    batch_size=64,
    image_size=(128, 128),
    shuffle=True,#mixing data
    seed=None,
    validation_split=None,#validation data is different no divide req
    interpolation="bilinear",#method for resizing
)

"""##model1

###Model building
"""

model1=tf.keras.models.Sequential()#defining the model
#adding convolutional layer
model1.add(tf.keras.layers.Conv2D(filters=64,kernel_size=3,activation='relu',input_shape=[128,128,3]))##------>try different models using different values and activation
#pooling layer
model1.add(tf.keras.layers.MaxPool2D(pool_size=2,strides=2))#moving two steps therefore 2 strides taking max of 2*2 hence pool size is 2 and maxpool
model1.add(tf.keras.layers.Conv2D(filters=64,kernel_size=3,activation='relu'))#again applying for reducing size further
model1.add(tf.keras.layers.MaxPool2D(pool_size=2,strides=2))
model1.add(tf.keras.layers.Dropout(0.5))#avoiding overfitting
model1.add(tf.keras.layers.Flatten())

#making neuron layers
model1.add(tf.keras.layers.Dense(units=128,activation='relu'))#number of neurons
model1.add(tf.keras.layers.Dense(units=36,activation='softmax'))#output layer softmax as its good in categorical

model1.compile(optimizer='rmsprop',loss='categorical_crossentropy',metrics=['accuracy'])##can also try rmsprop inplace of sgd

"""###Training"""

modeldata=model1.fit(x=train_set,validation_data=val_set,epochs=25)

"""###visualization

"""

dict1=modeldata.history
plt.plot([i for i in range(1,26)],dict1["val_accuracy"],c='purple')
plt.xlabel('No. of epochs')
plt.ylabel('Validation Accuracy')
plt.title('Accuracy Visualization')
plt.grid()
plt.xticks([i for i in range(1,26)])

plt.show()

plt.plot([i for i in range(1,26)],dict1["val_loss"])

plt.xlabel('No. of epochs')
plt.ylabel('Validation Loss')
plt.title('Accuracy Visualization')
plt.grid()
plt.xticks([i for i in range(1,26)])
plt.show()

plt.plot([i for i in range(1,26)],dict1["accuracy"],c='red')

plt.xlabel('No. of epochs')
plt.ylabel('Accuracy')
plt.title('Accuracy Visualization')
plt.grid()
plt.xticks([i for i in range(1,26)])
plt.show()

print('Final validation accuracy is coming out to be',dict1['val_accuracy'][-1])

"""###checking on testing data"""

fruits=test_set.class_names#returns list with class names at indexes
predictions = model1.predict(test_set)
acc = model1.evaluate(test_set)
print('Test accuracy:', acc[1])
print('Test Loss:', acc[0])

"""###now using for single image predictions"""

def image_prediction(path,model,imgsize,classes):
  #preprocessing image
  sample=tf.keras.preprocessing.image.load_img(path,target_size=(imgsize,imgsize))
  array=tf.keras.preprocessing.image.img_to_array(sample)
  input_ary=np.array([array])#it will make the input array as a 2d data so that single image can create a batch as the predict function works on dataset only
  #making prediction, it will return a 2d array
  output=model.predict(input_ary)
  #printing image
  image = Image.open(path)
  plt.imshow(image)
  plt.show()
  #printing prediction
  result=classes[np.argmax(output[0])]#as the result will be stored in zeroth array
  print('The predicted output is',result)

image_prediction('/content/train/apple/Image_59.png',model1,128,fruits)

for name in os.listdir('/content/test'):
    folder_path = os.path.join('/content/test', name) #creates the path of the current subfolder.
    for fruit in os.listdir(folder_path):
      fruitpath=os.path.join(folder_path, fruit)
      image_prediction(fruitpath,model1,128,fruits)

"""#Part 2

### Loading Training Data
"""

training_directory='/content/train' #address of data stored in drive using kaggle api
testing_directory='/content/test'
validation_directory='/content/validation'
train_set=tf.keras.utils.image_dataset_from_directory(
    training_directory,
    labels="inferred",#to take labels directly from subfolder names
    label_mode="categorical",#labels are encoded as a categorical vector
    color_mode="rgb",#colored or 3d images
    batch_size=64,
    image_size=(64, 64),
    shuffle=True,#mixing data
    seed=None,
    validation_split=None,#validation data is different no divide req
    interpolation="bilinear",#method for resizing
)

import matplotlib.pyplot as plt

# get the first batch of images and labels
for images, labels in train_set.take(1):
    # plot the first 9 images
    fig, axs = plt.subplots(3, 3, figsize=(10,10))
    axs = axs.flatten()
    for img, ax in zip(images, axs):
        ax.imshow(img.numpy().astype('uint8'))
        ax.axis('off')
    plt.tight_layout()
    plt.show()

"""data has been loaded for training set. now we will go for validation and testing data

###validation data
"""

val_set=tf.keras.utils.image_dataset_from_directory(
    validation_directory,
    labels="inferred",#to take labels directly from subfolder names
    label_mode="categorical",#labels are encoded as a categorical vector
    color_mode="rgb",#colored or 3d images
    batch_size=64,
    image_size=(64, 64),
    shuffle=True,#mixing data
    seed=None,
    validation_split=None,#validation data is different no divide req
    interpolation="bilinear",#method for resizing
)

"""###testing data"""

test_set=tf.keras.utils.image_dataset_from_directory(
    testing_directory,
    labels="inferred",#to take labels directly from subfolder names
    label_mode="categorical",#labels are encoded as a categorical vector
    color_mode="rgb",#colored or 3d images
    batch_size=64,
    image_size=(64, 64),
    shuffle=True,#mixing data
    seed=None,
    validation_split=None,#validation data is different no divide req
    interpolation="bilinear",#method for resizing
)

"""##model2

###Model building
"""

model1=tf.keras.models.Sequential()#defining the model
#adding convolutional layer
model1.add(tf.keras.layers.Conv2D(filters=32,kernel_size=3,activation='relu',input_shape=[64,64,3]))##------>try different models using different values and activation
#pooling layer
model1.add(tf.keras.layers.MaxPool2D(pool_size=2,strides=2))#moving two steps therefore 2 strides taking max of 2*2 hence pool size is 2 and maxpool
model1.add(tf.keras.layers.Conv2D(filters=64,kernel_size=3,activation='relu'))#again applying for reducing size further
model1.add(tf.keras.layers.MaxPool2D(pool_size=2,strides=2))
model1.add(tf.keras.layers.Dropout(0.5))#avoiding overfitting
model1.add(tf.keras.layers.Flatten())

#making neuron layers
model1.add(tf.keras.layers.Dense(units=150,activation='relu'))#number of neurons
model1.add(tf.keras.layers.Dense(units=125,activation='relu'))#number of neurons
model1.add(tf.keras.layers.Dense(units=100,activation='relu'))#number of neurons
model1.add(tf.keras.layers.Dense(units=60,activation='relu'))#number of neurons
model1.add(tf.keras.layers.Dense(units=36,activation='softmax'))#output layer softmax as its good in categorical

model1.compile(optimizer='rmsprop',loss='categorical_crossentropy',metrics=['accuracy'])##can also try rmsprop inplace of sgd

"""###Training"""

modeldata=model1.fit(x=train_set,validation_data=val_set,epochs=15)

"""###visualization

"""

dict1=modeldata.history
plt.plot([i for i in range(1,16)],dict1["val_accuracy"],c='purple')
plt.xlabel('No. of epochs')
plt.ylabel('Validation Accuracy')
plt.title('Accuracy Visualization')
plt.grid()
plt.xticks([i for i in range(1,16)])

plt.show()

plt.plot([i for i in range(1,16)],dict1["val_loss"])

plt.xlabel('No. of epochs')
plt.ylabel('Validation Loss')
plt.title('Accuracy Visualization')
plt.grid()
plt.xticks([i for i in range(1,16)])
plt.show()

plt.plot([i for i in range(1,16)],dict1["accuracy"],c='red')

plt.xlabel('No. of epochs')
plt.ylabel('Accuracy')
plt.title('Accuracy Visualization')
plt.grid()
plt.xticks([i for i in range(1,16)])
plt.show()

print('Final validation accuracy is coming out to be',dict1['val_accuracy'][-1])

"""###checking on testing data"""

fruits=test_set.class_names#returns list with class names at indexes
predictions = model1.predict(test_set)
acc = model1.evaluate(test_set)
print('Test accuracy:', acc[1])
print('Test Loss:', acc[0])

"""###now using for single image predictions"""

def image_prediction(path,model,imgsize,classes):
  #preprocessing image
  sample=tf.keras.preprocessing.image.load_img(path,target_size=(imgsize,imgsize))
  array=tf.keras.preprocessing.image.img_to_array(sample)
  input_ary=np.array([array])#it will make the input array as a 2d data so that single image can create a batch as the predict function works on dataset only
  #making prediction, it will return a 2d array
  output=model.predict(input_ary)
  #printing image
  image = Image.open(path)
  plt.imshow(image)
  plt.show()
  #printing prediction
  result=classes[np.argmax(output[0])]#as the result will be stored in zeroth array
  print('The predicted output is',result)

image_prediction('/content/train/apple/Image_59.png',model1,64,fruits)

for name in os.listdir('/content/test'):
    folder_path = os.path.join('/content/test', name) #creates the path of the current subfolder.
    for fruit in os.listdir(folder_path):
      fruitpath=os.path.join(folder_path, fruit)
      image_prediction(fruitpath,model1,64,fruits)

"""#Part3

##Loading Training Data
"""

training_directory='/content/train' #address of data stored in drive using kaggle api
testing_directory='/content/test'
validation_directory='/content/validation'
train_set=tf.keras.utils.image_dataset_from_directory(
    training_directory,
    labels="inferred",#to take labels directly from subfolder names
    label_mode="categorical",#labels are encoded as a categorical vector
    color_mode="rgb",#colored or 3d images
    batch_size=64,
    image_size=(128, 128),
    shuffle=True,#mixing data
    seed=None,
    validation_split=None,#validation data is different no divide req
    interpolation="bilinear",#method for resizing
)

import matplotlib.pyplot as plt

# get the first batch of images and labels
for images, labels in train_set.take(1):
    # plot the first 9 images
    fig, axs = plt.subplots(3, 3, figsize=(10,10))
    axs = axs.flatten()
    for img, ax in zip(images, axs):
        ax.imshow(img.numpy().astype('uint8'))
        ax.axis('off')
    plt.tight_layout()
    plt.show()

"""data has been loaded for training set. now we will go for validation and testing data

###validation data
"""

val_set=tf.keras.utils.image_dataset_from_directory(
    validation_directory,
    labels="inferred",#to take labels directly from subfolder names
    label_mode="categorical",#labels are encoded as a categorical vector
    color_mode="rgb",#colored or 3d images
    batch_size=64,
    image_size=(128, 128),
    shuffle=True,#mixing data
    seed=None,
    validation_split=None,#validation data is different no divide req
    interpolation="bilinear",#method for resizing
)

"""###testing data"""

test_set=tf.keras.utils.image_dataset_from_directory(
    testing_directory,
    labels="inferred",#to take labels directly from subfolder names
    label_mode="categorical",#labels are encoded as a categorical vector
    color_mode="rgb",#colored or 3d images
    batch_size=64,
    image_size=(128, 128),
    shuffle=True,#mixing data
    seed=None,
    validation_split=None,#validation data is different no divide req
    interpolation="bilinear",#method for resizing
)

"""##model1

###Model building
"""

model1=tf.keras.models.Sequential()#defining the model
#adding convolutional layer
model1.add(tf.keras.layers.Conv2D(filters=64,kernel_size=3,activation='relu',input_shape=[128,128,3]))##------>try different models using different values and activation
#pooling layer
model1.add(tf.keras.layers.MaxPool2D(pool_size=2,strides=2))#moving two steps therefore 2 strides taking max of 2*2 hence pool size is 2 and maxpool
model1.add(tf.keras.layers.Conv2D(filters=64,kernel_size=3,activation='relu'))#again applying for reducing size further
model1.add(tf.keras.layers.MaxPool2D(pool_size=2,strides=2))
model1.add(tf.keras.layers.Dropout(0.5))#avoiding overfitting
model1.add(tf.keras.layers.Flatten())

#making neuron layers
model1.add(tf.keras.layers.Dense(units=128,activation='relu'))#number of neurons
model1.add(tf.keras.layers.Dense(units=90,activation='relu'))#number of neurons
model1.add(tf.keras.layers.Dense(units=50,activation='relu'))#number of neurons
model1.add(tf.keras.layers.Dense(units=36,activation='softmax'))#output layer softmax as its good in categorical

model1.compile(optimizer='rmsprop',loss='categorical_crossentropy',metrics=['accuracy'])##can also try rmsprop inplace of sgd

"""###Training"""

modeldata=model1.fit(x=train_set,validation_data=val_set,epochs=15)

"""###visualization

"""

dict1=modeldata.history
plt.plot([i for i in range(1,16)],dict1["val_accuracy"],c='purple')
plt.xlabel('No. of epochs')
plt.ylabel('Validation Accuracy')
plt.title('Accuracy Visualization')
plt.grid()
plt.xticks([i for i in range(1,16)])

plt.show()

plt.plot([i for i in range(1,16)],dict1["val_loss"])

plt.xlabel('No. of epochs')
plt.ylabel('Validation Loss')
plt.title('Accuracy Visualization')
plt.grid()
plt.xticks([i for i in range(1,16)])
plt.show()

plt.plot([i for i in range(1,16)],dict1["accuracy"],c='red')

plt.xlabel('No. of epochs')
plt.ylabel('Accuracy')
plt.title('Accuracy Visualization')
plt.grid()
plt.xticks([i for i in range(1,16)])
plt.show()

print('Final validation accuracy is coming out to be',dict1['val_accuracy'][-1])

"""###checking on testing data"""

fruits=test_set.class_names#returns list with class names at indexes
predictions = model1.predict(test_set)
acc = model1.evaluate(test_set)
print('Test accuracy:', acc[1])
print('Test Loss:', acc[0])
# print('Test precision:', acc[2])

"""###now using for single image predictions"""

def image_prediction(path,model,imgsize,classes):
  #preprocessing image
  sample=tf.keras.preprocessing.image.img_to_array(path,target_size=(imgsize,imgsize))
  array=tf.keras.preprocessing.image.img_to_array(sample)
  input_ary=np.array([array])#it will make the input array as a 2d data so that single image can create a batch as the predict function works on dataset only
  #making prediction, it will return a 2d array
  output=model.predict(input_ary)
  #printing image
  image = Image.open(path)
  plt.imshow(image)
  plt.show()
  #printing prediction
  result=classes[np.argmax(output[0])]#as the result will be stored in zeroth array
  print('The predicted output is',result)

"""#Part 4"""



"""### Loading Training Data"""

training_directory='/content/train' #address of data stored in drive using kaggle api
testing_directory='/content/test'
validation_directory='/content/validation'
train_set=tf.keras.utils.image_dataset_from_directory(
    training_directory,
    labels="inferred",#to take labels directly from subfolder names
    label_mode="categorical",#labels are encoded as a categorical vector
    color_mode="rgb",#colored or 3d images
    batch_size=64,
    image_size=(128, 128),
    shuffle=True,#mixing data
    seed=None,
    validation_split=None,#validation data is different no divide req
    interpolation="bilinear",#method for resizing
)

import matplotlib.pyplot as plt

# get the first batch of images and labels
for images, labels in train_set.take(1):
    # plot the first 9 images
    fig, axs = plt.subplots(3, 3, figsize=(10,10))
    axs = axs.flatten()
    for img, ax in zip(images, axs):
        ax.imshow(img.numpy().astype('uint8'))
        ax.axis('off')
    plt.tight_layout()
    plt.show()

"""data has been loaded for training set. now we will go for validation and testing data

###validation data
"""

val_set=tf.keras.utils.image_dataset_from_directory(
    validation_directory,
    labels="inferred",#to take labels directly from subfolder names
    label_mode="categorical",#labels are encoded as a categorical vector
    color_mode="rgb",#colored or 3d images
    batch_size=64,
    image_size=(128, 128),
    shuffle=True,#mixing data
    seed=None,
    validation_split=None,#validation data is different no divide req
    interpolation="bilinear",#method for resizing
)

"""###testing data"""

test_set=tf.keras.utils.image_dataset_from_directory(
    testing_directory,
    labels="inferred",#to take labels directly from subfolder names
    label_mode="categorical",#labels are encoded as a categorical vector
    color_mode="rgb",#colored or 3d images
    batch_size=64,
    image_size=(128, 128),
    shuffle=True,#mixing data
    seed=None,
    validation_split=None,#validation data is different no divide req
    interpolation="bilinear",#method for resizing
)

"""##model1

###Model building
"""

model1=tf.keras.models.Sequential()#defining the model
#adding convolutional layer
model1.add(tf.keras.layers.Conv2D(filters=64,kernel_size=3,activation='relu',input_shape=[128,128,3]))##------>try different models using different values and activation
#pooling layer
model1.add(tf.keras.layers.MaxPool2D(pool_size=2,strides=2))#moving two steps therefore 2 strides taking max of 2*2 hence pool size is 2 and maxpool
model1.add(tf.keras.layers.Conv2D(filters=64,kernel_size=3,activation='relu'))#again applying for reducing size further
model1.add(tf.keras.layers.MaxPool2D(pool_size=2,strides=2))
model1.add(tf.keras.layers.Dropout(0.5))#avoiding overfitting
model1.add(tf.keras.layers.Flatten())

#making neuron layers
model1.add(tf.keras.layers.Dense(units=500,activation='relu'))#number of neurons
model1.add(tf.keras.layers.Dense(units=36,activation='softmax'))#output layer softmax as its good in categorical

model1.compile(optimizer='rmsprop',loss='categorical_crossentropy',metrics=['accuracy'])##can also try rmsprop inplace of sgd

"""###Training"""

modeldata=model1.fit(x=train_set,validation_data=val_set,epochs=15)

"""###visualization

"""

dict1=modeldata.history
plt.plot([i for i in range(1,16)],dict1["val_accuracy"],c='purple')
plt.xlabel('No. of epochs')
plt.ylabel('Validation Accuracy')
plt.title('Accuracy Visualization')
plt.grid()
plt.xticks([i for i in range(1,16)])

plt.show()

plt.plot([i for i in range(1,16)],dict1["val_loss"])

plt.xlabel('No. of epochs')
plt.ylabel('Validation Loss')
plt.title('Accuracy Visualization')
plt.grid()
plt.xticks([i for i in range(1,16)])
plt.show()

plt.plot([i for i in range(1,16)],dict1["accuracy"],c='red')

plt.xlabel('No. of epochs')
plt.ylabel('Accuracy')
plt.title('Accuracy Visualization')
plt.grid()
plt.xticks([i for i in range(1,16)])
plt.show()

print('Final validation accuracy is coming out to be',dict1['val_accuracy'][-1])

"""###checking on testing data"""

fruits=test_set.class_names#returns list with class names at indexes
predictions = model1.predict(test_set)
acc = model1.evaluate(test_set)
print('Test accuracy:', acc[1])
print('Test Loss:', acc[0])
# print('Test precision:', acc[2])

"""###now using for single image predictions"""

def image_prediction(path,model,imgsize,classes):
  #preprocessing image
  sample=tf.keras.preprocessing.image.img_to_array(path,target_size=(imgsize,imgsize))
  array=tf.keras.preprocessing.image.img_to_array(sample)
  input_ary=np.array([array])#it will make the input array as a 2d data so that single image can create a batch as the predict function works on dataset only
  #making prediction, it will return a 2d array
  output=model.predict(input_ary)
  #printing image
  image = Image.open(path)
  plt.imshow(image)
  plt.show()
  #printing prediction
  result=classes[np.argmax(output[0])]#as the result will be stored in zeroth array
  print('The predicted output is',result)

"""#part 5"""



model1=tf.keras.models.Sequential()#defining the model
#adding convolutional layer
model1.add(tf.keras.layers.Conv2D(filters=32,kernel_size=3,activation='relu',input_shape=[256,256,3]))##------>try different models using different values and activation
#pooling layer
model1.add(tf.keras.layers.MaxPool2D(pool_size=2,strides=2))#moving two steps therefore 2 strides taking max of 2*2 hence pool size is 2 and maxpool
model1.add(tf.keras.layers.Conv2D(filters=64,kernel_size=3,activation='relu'))#again applying for reducing size further
model1.add(tf.keras.layers.MaxPool2D(pool_size=2,strides=2))
model1.add(tf.keras.layers.Dropout(0.5))#avoiding overfitting
model1.add(tf.keras.layers.Flatten())

#making neuron layers
model1.add(tf.keras.layers.Dense(units=60,activation='relu'))#number of neurons
model1.add(tf.keras.layers.Dense(units=36,activation='softmax'))#output layer softmax as its good in categorical

model1.compile(optimizer='rmsprop',loss='categorical_crossentropy',metrics=['accuracy'])##can also try rmsprop inplace of sgd

modeldata=model1.fit(x=train_set,validation_data=val_set,epochs=15)

dict1=modeldata.history
plt.plot([i for i in range(1,16)],dict1["val_accuracy"],c='purple')
plt.xlabel('No. of epochs')
plt.ylabel('Validation Accuracy')
plt.title('Accuracy Visualization')
plt.grid()
plt.xticks([i for i in range(1,16)])

plt.show()