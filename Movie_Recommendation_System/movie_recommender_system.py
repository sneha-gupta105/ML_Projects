# -*- coding: utf-8 -*-
"""Movie_Recommender_System.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1NegQWyAAAqNf77P7xJV4eAyZL_c5756I
"""

# from matplotlib import pyplot as plt
# import numpy as np

# # Generate 100 random data points along 3 dimensions
# x, y, scale = np.random.randn(3, 100)
# fig, ax = plt.subplots()

# # Map each onto a scatterplot we'll create with Matplotlib
# ax.scatter(x=x, y=y, c=scale, s=np.abs(scale)*500)
# ax.set(title="Some random data, created with JupyterLab!")
# plt.show()

"""**Types of recommender system**
1. Content-based(content similarity)
2. Collaborative filtering(user similarity)
3. Hybrid

Project Overview:
Data --> Preprocessing --> Model Building --> Website --> Deploy

Dataset(TMDB 5000 Movie Dataset)
1. tmdb_5000_credits ---> id, name, Cast, crew
2. tmdb_5000_movies ---> budget, genre, homepage, id, keywords, original_language, orginal_title, overview. popularity, production_company, production_countries, release_date, revenue, runtime, spoken_languages, status, tagline, title, vote_average, vote_count
"""

import numpy as np
import pandas as pd

"""# Data"""

movies = pd.read_csv("/content/drive/MyDrive/archive/tmdb_5000_movies.csv")
credits = pd.read_csv("/content/drive/MyDrive/archive/tmdb_5000_credits.csv")

movies.rename(columns = {'id':'movie_id'}, inplace = True)

movies.head()

credits.head()

credits.head(1)['crew'].values

"""First we need to merge both the data frame. We can merge on the basis of either Id or title.



"""

movies.merge(credits, on = 'movie_id').shape

movies = movies.merge(credits, on = 'movie_id')

movies.head(1)

movies['original_language'].value_counts()

"""We need a content based recommender system. So, we need to check which columns can help in creating tags and we will keep those columns only.
1. Budget   --> No
2. Genre    --> Yes
3. Homepage --> No
4. Id       --> Yes(for movie posters, we'll fetch the posters through id)
5. Keywords --> Yes
6. Original_Language --> No (Out of 5000 movies 4500 are english, so we don't need to keep this column as well)
7. Original_Title --> No (We'll keep 'title' rather because that will be in english only)
8. Overview   --> Yes
9. Popularity --> No (Doesn't go well with our approach)
10. Production_Company --> No
11. Production_Countries --> No
12. Release_Date --> No(Could be a factor but we are not using this)
13. Revenue --> No
14. Runtime --> No
15. Spoken_Languages --> No
16. Status  --> No
17. Tagline --> No (Vague)
18. Title   --> Yes
19. Vote_average --> No
20. Vote_count --> No
21. Movie_id --> No
22. Cast    --> Yes
23. Crew    --> Yes
"""

movies1 = movies[['movie_id','title_x', 'overview', 'genres', 'keywords', 'cast', 'crew']]

movies1.head()

"""We need to make a new dataframe, which contains movie_id, title, tags(contains overview, genres, keywords, cast, crew)

tag --> genre, keywords in clear format, top 3 cast, director from the crew
"""



"""# Preprocessing"""

# Check for missing data
movies1.isnull().sum()

# Drop the three columns where overview is missing
movies1.dropna(inplace = True)

# To check for duplicate values
movies1.duplicated().sum()

# Check for each column data, e.g. genre(dictionery)
movies1.iloc[0].genres

# Present Format --> '[{"id": 28, "name": "Action"}, {"id": 12, "name": "Adventure"}, {"id": 14, "name": "Fantasy"}, {"id": 878, "name": "Science Fiction"}]'
# Desired Format --> ['Action', 'Adventure', 'Fantasy', 'Science Fiction']
# Create a helper function
# Convert string of list to list
import ast
def convert(obj):
  L = []
  for i in ast.literal_eval(obj):
    L.append(i['name'])
  return L

movies1['genres'] = movies1['genres'].apply(convert)

movies1['keywords'] = movies1['keywords'].apply(convert)
movies1.head()

# For cast column, we need only top three actors(first three dictioneries and also only the value with key = "name")
import ast
def convert3(obj):
  L = []
  counter = 0
  for i in ast.literal_eval(obj):
    if(counter != 3):
      L.append(i['name'])
      counter += 1
    else:
      break
  return L

# Call the function on cast column
movies1['cast'] = movies1['cast'].apply(convert3)
movies1.head()

# In the crew column, we only need to keep the name of the director, so we need the column where "job": Director
def fetch_director(obj):
  L = []
  for i in ast.literal_eval(obj):
    if(i['job'] == 'Director'):
      L.append(i['name'])
      break
  return L

# Call this function on crew column
movies1['crew'] = movies1['crew'].apply(fetch_director)
movies1.head()

# For overview column, we'll convert it to a list(currently it is a string)
movies1['overview'] = movies1['overview'].apply(lambda x:x.split())
movies1.head()

# Now, we need to concatenate all four columns to get a list for tag column
# We need 'Sam Worthington' --> 'SamWorthington' because we have another person whose name is 'Sam Mendes'
# so to avoid having similar tags, we need to remove the spaces
movies1['genres'] = movies1['genres'].apply(lambda x:[i.replace(" ","") for i in x])
movies1['keywords'] = movies1['keywords'].apply(lambda x:[i.replace(" ","") for i in x])
movies1['cast'] = movies1['cast'].apply(lambda x:[i.replace(" ","") for i in x])
movies1['crew'] = movies1['crew'].apply(lambda x:[i.replace(" ","") for i in x])

# Now concatenate all four lists and make a new column with name "tags"
movies1['tags'] = movies1['overview'] + movies1['genres'] + movies1['cast'] + movies1['crew']
movies1.head()

# Make a new dataframe with only 3  columns -->  movie_id, title_x, tags
new_df = movies1[['movie_id', 'title_x', 'tags']]
new_df

# now convert the list to string again
new_df['tags'] = new_df['tags'].apply(lambda x:" ".join(x))

# Convert the whole string to lowercase
new_df['tags'] = new_df['tags'].apply(lambda x:x.lower())
new_df['tags'][0]

"""# Text Vectorization

We need to build a website where a user gives us the name of a movie and we need to provide 5 most similar movies as the input on the basis of tags.

**Challenge** --> Calculate the similarity between two tags.

**Lame method** --> Calculate the no. of similar words.

**Better Method** --> Vectorize the tag(make the tag of each movie as a vector and then we will find the five nearest vectors to our vector and recommend the movies.

**Text Vectorzation Technique**: *Bag of words* --> We combine(concatenate) all the tags of the movie and then we find the *n* (say 5000) no. of most common words. Calculate the frequency of top 5000 words. Then calculate the no. of occurance of these words in other movies. And this table of 5000 movies * 5000 words has 5000 vectors for each movie in a 5000 dimensional space. And now find the closest 5 movies on the basis of these vectors. We can take as many words as we want. We should take less words for better performance. During vectorizatino, we won't use stop words(i.e. in, a, the, are, to, from, etc.) We can do all this using a function from sklearn library.
"""

# Stemming --> ['loved','loving','loves'] --> ['love','love','love']
# For this we need a library called nltk
!pip install nltk

from nltk.stem.porter import PorterStemmer
ps = PorterStemmer()

def stem(text):
  y = []
  for i in text.split():
    y.append(ps.stem(i))
  return " ".join(y)

new_df['tags'] = new_df['tags'].apply(stem)

from sklearn.feature_extraction.text import CountVectorizer
cv = CountVectorizer(max_features = 5000, stop_words = 'english')

vectors = cv.fit_transform(new_df['tags']).toarray()

vectors.shape

#cv.get_feature_names()

"""# Main Function"""

# We have 4800 movies and therefore we have 4800 vectors
# We will calculate the cosine distance between these vectors(angle between vectors)
# We have a function called cosine similarity in sklearn for this
from sklearn.metrics.pairwise import cosine_similarity
similarity = cosine_similarity(vectors)

similarity.shape
# distance of each movie with all other movies

sorted(list(enumerate(similarity[0])), reverse = True, key = lambda x:x[1])[1:6]

# given a movie in the recommend function, we need to find its index in our data,
# then using that index we'll go to the similarity matrix and find the max 5 values and output those.
def recommend(movie):
  movie_index = new_df[new_df['title_x'] == movie].index[0]
  distances = similarity[movie_index]
  # Sort the distances but keep the indices intact
  movies_list = sorted(list(enumerate(distances)), reverse = True, key = lambda x:x[1])[1:6]
  for i in movies_list:
    print(new_df.iloc[i[0]].title_x)

recommend('Life of Pi')